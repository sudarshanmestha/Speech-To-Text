🚀 Just launched my audio transcription web app using OpenAI's Whisper + Streamlit!

🎙️ Upload an audio file, and it returns:
✅ Timestamped transcription
✅ Speaker detection (interviewer/candidate)
✅ Cleanly formatted output
Built it to practice NLP and AI deployment end-to-end.

🔗 Try it out here: [your Render link]
🧠 Code: [GitHub repo link]

#AI #NLP #Whisper #Streamlit #MLOps #OpenSource #PortfolioProject #Career






# 🎙️ Whisper Audio Transcriber

An end-to-end **audio transcription web app** using [OpenAI Whisper](https://github.com/openai/whisper) and [Streamlit](https://streamlit.io/).

Upload an audio file (MP3, WAV, M4A) and get:

✅ Timestamped transcription  
✅ Speaker labeling (Interviewer/Candidate)  
✅ Clean sentence formatting  
✅ Simple web UI – no installation required

---

## 🚀 Demo

🌐 Live App: [https://your-render-link-here.com](https://your-render-link-here.com)



---

## 📦 Features

- Uses **Whisper base model** for fast and accurate transcription.
- Basic **speaker attribution** based on question/answer heuristics.
- Outputs **timestamped** transcripts.
- Fully deployable with **Render**, **Streamlit Cloud**, or **locally**.

---

## 🖥️ Local Setup

### 🔧 Prerequisites

- Python 3.9+
- ffmpeg (must be installed system-wide)
- Git

### 🧪 Installation

```bash
git clone https://github.com/yourusername/whisper-transcriber.git
cd whisper-transcriber
pip install -r requirements.txt

▶️ Run the App
streamlit run app.py
Then visit http://localhost:8501 in your browser.


📁 File Structure
├── app.py               # Main Streamlit app
├── requirements.txt     # Python dependencies
└── README.md            # This file

🛠️ Tech Stack
🧠 Whisper by OpenAI (ASR)

🕸️ Streamlit for UI

🐍 Python

🌍 Render for deployment

🙌 Acknowledgements
OpenAI Whisper

Streamlit

tqdm for progress bars (optional)

📢 License
MIT License

✨ Author
Built with ❤️ by Jana