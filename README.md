ğŸš€ Just launched my audio transcription web app using OpenAI's Whisper + Streamlit!

ğŸ™ï¸ Upload an audio file, and it returns:
âœ… Timestamped transcription
âœ… Speaker detection (interviewer/candidate)
âœ… Cleanly formatted output
Built it to practice NLP and AI deployment end-to-end.

ğŸ”— Try it out here: [your Render link]
ğŸ§  Code: [GitHub repo link]

#AI #NLP #Whisper #Streamlit #MLOps #OpenSource #PortfolioProject #Career






# ğŸ™ï¸ Whisper Audio Transcriber

An end-to-end **audio transcription web app** using [OpenAI Whisper](https://github.com/openai/whisper) and [Streamlit](https://streamlit.io/).

Upload an audio file (MP3, WAV, M4A) and get:

âœ… Timestamped transcription  
âœ… Speaker labeling (Interviewer/Candidate)  
âœ… Clean sentence formatting  
âœ… Simple web UI â€“ no installation required

---

## ğŸš€ Demo

ğŸŒ Live App: [https://your-render-link-here.com](https://your-render-link-here.com)



---

## ğŸ“¦ Features

- Uses **Whisper base model** for fast and accurate transcription.
- Basic **speaker attribution** based on question/answer heuristics.
- Outputs **timestamped** transcripts.
- Fully deployable with **Render**, **Streamlit Cloud**, or **locally**.

---

## ğŸ–¥ï¸ Local Setup

### ğŸ”§ Prerequisites

- Python 3.9+
- ffmpeg (must be installed system-wide)
- Git

### ğŸ§ª Installation

```bash
git clone https://github.com/yourusername/whisper-transcriber.git
cd whisper-transcriber
pip install -r requirements.txt

â–¶ï¸ Run the App
streamlit run app.py
Then visit http://localhost:8501 in your browser.


ğŸ“ File Structure
â”œâ”€â”€ app.py               # Main Streamlit app
â”œâ”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ README.md            # This file

ğŸ› ï¸ Tech Stack
ğŸ§  Whisper by OpenAI (ASR)

ğŸ•¸ï¸ Streamlit for UI

ğŸ Python

ğŸŒ Render for deployment

ğŸ™Œ Acknowledgements
OpenAI Whisper

Streamlit

tqdm for progress bars (optional)

ğŸ“¢ License
MIT License

âœ¨ Author
Built with â¤ï¸ by Jana